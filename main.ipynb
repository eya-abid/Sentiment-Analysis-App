{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UVphOoN8CaG",
        "outputId": "9cc2bbad-2eae-49f3-f9af-f487e8b72fdc"
      },
      "source": [
        "!pip install fastapi nest-asyncio pyngrok uvicorn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.65.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.0.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: starlette==0.14.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.14.2)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Requirement already satisfied: asgiref>=3.3.4 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.7.4.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (0.12.0)\n",
            "Requirement already satisfied: click>=7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxqo07-c8KZd"
      },
      "source": [
        "import numpy as np\n",
        "from fastapi import FastAPI, Form\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import pandas as pd\n",
        "from starlette.responses import HTMLResponse\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import re"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDKtJTLu8cSA"
      },
      "source": [
        "app = FastAPI()\n",
        "\n",
        "@app.get('/predict', response_class=HTMLResponse)\n",
        "def take_inp():\n",
        "    return '''\n",
        "        <form method=\"post\">\n",
        "        <input maxlength=\"28\" name=\"text\" type=\"text\" value=\"Text Emotion to be tested\" />\n",
        "        <input type=\"submit\" />'''"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdanB9JK8mvV",
        "outputId": "07b837ec-87c6-44a8-d06b-0edaca9b9745"
      },
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: http://22821470d305.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [326]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [326]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9SC3ohp-uTS"
      },
      "source": [
        "data = pd.read_csv('Sentiment.csv')\n",
        "tokenizer = Tokenizer(num_words=2000, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "#We will create a function to remove unwanted characters in Tweets using Regex.\n",
        "#We will use Tensorflow’s tokenizer to tokenize our dataset, and Tensorflow’s pad_sequences to pad our sequences.\n",
        "\n",
        "def preProcess_data(text):\n",
        "    text = text.lower()\n",
        "    new_text = re.sub('[^a-zA-z0-9\\s]','',text)\n",
        "    new_text = re.sub('rt', '', new_text)\n",
        "    return new_text\n",
        "\n",
        "def my_pipeline(text):\n",
        "    text_new = preProcess_data(text)\n",
        "    X = tokenizer.texts_to_sequences(pd.Series(text_new).values)\n",
        "    X = pad_sequences(X, maxlen=28)\n",
        "    return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGkcn8TG_gnG",
        "outputId": "b68c0438-18ee-4b48-8179-583ac94bd8e4"
      },
      "source": [
        "!pip install python-multipart"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.7/dist-packages (0.0.5)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from python-multipart) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKRDtR7k_MZl"
      },
      "source": [
        "@app.post('/predict')\n",
        "def predict(text:str = Form(...)):\n",
        "    clean_text = my_pipeline(text) #clean, and preprocess the text through pipeline\n",
        "    loaded_model = tf.keras.models.load_model('sentiment.h5') #load the saved model \n",
        "    predictions = loaded_model.predict(clean_text) #predict the text\n",
        "    sentiment = int(np.argmax(predictions)) #calculate the index of max sentiment\n",
        "    probability = max(predictions.tolist()[0]) #calulate the probability\n",
        "    if sentiment==0:\n",
        "         t_sentiment = 'negative' #set appropriate sentiment\n",
        "    elif sentiment==1:\n",
        "         t_sentiment = 'neutral'\n",
        "    elif sentiment==2:\n",
        "         t_sentiment='postive'\n",
        "    return { #return the dictionary for endpoint\n",
        "         \"ACTUALL SENTENCE\": text,\n",
        "         \"PREDICTED SENTIMENT\": t_sentiment,\n",
        "         \"Probability\": probability\n",
        "    }\n",
        "@app.get('/')\n",
        "def basic_view():\n",
        "    return {\"WELCOME\": \"GO TO /docs route, or /post or send post request to /predict \"}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKII-thO_ry1",
        "outputId": "e285f8ff-63e5-48bb-825d-82f71afc74b7"
      },
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: http://f97cbb5b0421.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [326]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     102.110.22.102:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     102.110.22.102:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     102.110.22.102:0 - \"GET /predict HTTP/1.1\" 200 OK\n",
            "INFO:     102.110.22.102:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     102.110.22.102:0 - \"GET /predict HTTP/1.1\" 200 OK\n",
            "INFO:     102.110.22.102:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     102.110.22.102:0 - \"GET /predict HTTP/1.1\" 200 OK\n",
            "INFO:     102.110.22.102:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     102.110.22.102:0 - \"GET /predict HTTP/1.1\" 200 OK\n",
            "INFO:     102.110.22.102:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [326]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}