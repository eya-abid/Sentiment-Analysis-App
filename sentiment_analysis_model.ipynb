{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUuDD2mqNgbV"
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdV2Kp-SOaGH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "5811e93e-c719-4833-fea9-9306541f3bb1"
      },
      "source": [
        "data = pd.read_csv('Sentiment.csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text sentiment\n",
              "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n",
              "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
              "2  RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n",
              "3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
              "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suRrA_aBPRHr"
      },
      "source": [
        "# remove unwanted characters in Tweets using Regex\n",
        "def preProcess_data(text):\n",
        "   text = text.lower()\n",
        "   new_text = re.sub('[^a-zA-z0-9\\s]','',text)\n",
        "   new_text = re.sub('rt', '', new_text)\n",
        "   return new_text\n",
        "\n",
        "\n",
        "data['text'] = data['text'].apply(preProcess_data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNc0XcuyPWUv"
      },
      "source": [
        "#using Tensorflow’s tokenizer to tokenize our dataset, and Tensorflow’s pad_sequences to pad our sequences\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X, 28)\n",
        "\n",
        "Y = pd.get_dummies(data['sentiment']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeG0TSXXPez9"
      },
      "source": [
        "#splitting the dataset into training and testing portions.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20)\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(128,recurrent_dropout=0.2))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTgNafKJPsc6",
        "outputId": "9498b540-0221-4afb-be4f-161378e711ea"
      },
      "source": [
        "\n",
        "batch_size = 512\n",
        "\n",
        "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - 33s 1s/step - loss: 0.9448 - accuracy: 0.6065 - val_loss: 0.8902 - val_accuracy: 0.6079\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 27s 1s/step - loss: 0.8312 - accuracy: 0.6271 - val_loss: 0.7896 - val_accuracy: 0.6519\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 28s 1s/step - loss: 0.7418 - accuracy: 0.6730 - val_loss: 0.7557 - val_accuracy: 0.6714\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 27s 1s/step - loss: 0.6814 - accuracy: 0.7039 - val_loss: 0.7478 - val_accuracy: 0.6854\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 28s 1s/step - loss: 0.6413 - accuracy: 0.7236 - val_loss: 0.7382 - val_accuracy: 0.6825\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 27s 1s/step - loss: 0.6144 - accuracy: 0.7386 - val_loss: 0.7503 - val_accuracy: 0.6905\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 27s 1s/step - loss: 0.5879 - accuracy: 0.7444 - val_loss: 0.7730 - val_accuracy: 0.6825\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 27s 1s/step - loss: 0.5761 - accuracy: 0.7558 - val_loss: 0.7757 - val_accuracy: 0.6804\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 28s 1s/step - loss: 0.5654 - accuracy: 0.7591 - val_loss: 0.7803 - val_accuracy: 0.6825\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 27s 1s/step - loss: 0.5549 - accuracy: 0.7656 - val_loss: 0.7893 - val_accuracy: 0.6847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7d14992d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xASUsR6aQOQA"
      },
      "source": [
        "model.save('sentiment.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}